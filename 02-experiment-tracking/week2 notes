# Step 1: Prepare the local environment
# create environment
conda create -n exp-tracking-env python=3.9
# activate environment
conda activate exp-tracking-env
# once activated env, install required packages
pip install -r requirements.txt

# Step 2: Install MLflow client and configure a backend
# cd to correct directory, otherwise the mlflow server will not work
cd 02-experiment-tracking
# setup backend database for mlflow
mlflow ui --backend-store-uri sqlite:///mlflow.db
# open http://127.0.0.1:5000 in browser
# run jupyter notebook to test the code

# in the ipynb file: change the kernel to the created environment exp-tracking-env
# make sure to install the jupyter extension in VSCode, need reflesh the window to activate
# you will see the kernel changed to exp-tracking-env at the top right corner

# Step 3: add mlflow to existing notebook, log the predictions, show it in MLflow UI
import mlflow
mlflow.set_tracking_uri("sqlite:///mlflow.db")
mlflow.set_experiment("nyc-taxi-experiment")

# Step 4: add parameter tuning to the notebook

# Step 5: how it works in mlflow

# Step 6: select best one

# Step 7: autolog

# model management: Step 8: logging models in mlflow
# 2 options: 
# 1. log model as an artifact
mlflow.log_artifact("model.pkl", artifact_path="models/")
# 2. log model using the method log_model
mlflow.<framework>.log_model(model,  artifact_path="models/")



### Homework:
# Tip: go to 02-experiment-tracking/homework/ folder before executing the command 
# and change the value of <TAXI_DATA_FOLDER> to the location where you saved the data.
python preprocess_data.py --raw_data_path <TAXI_DATA_FOLDER> --dest_path ./output

python preprocess_data.py --raw_data_path ../data --dest_path ./output

python train.py

python hpo.py

python register_model.py --top_n 1