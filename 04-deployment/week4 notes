## Deploying a model as a web-service

* Creating a virtual environment with Pipenv
* Creating a script for predictiong 
* Putting the script into a Flask app
* Packaging the app to Docker


```bash
docker build -t ride-duration-prediction-service:v1 .
```

```bash
docker run -it --rm -p 9696:9696  ride-duration-prediction-service:v1
```

## we get the lin_reg.bin in week1 by 
with open('models/lin_reg.bin', 'wb') as f_out:
    pickle.dump((dv, lr), f_out)


# locate to directory
cd 04-deployment
cd web-service

pip freeze | grep scikit-learn
# creating virtual environment, it contains libaraies with specific application
pipenv install scikit-learn==1.0.2 flask numpy==1.21.6 --python=3.9

# to activate this virtual env, run
pipenv shell
# change the prompt
PS1="> "

# run Flask app
python predict.py
# open another terminal, test predict.py
python test.py

# Flask is only used for deployment purposes
# you will get warnings: WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.

# install gunicorn
pipenv install gunicorn

# instead of flask we use gunicorn to connect to the same application
gunicorn --bind=0.0.0.0:9696 predict:app

# install the package as a dev dependency
pipenv install --dev requests


# Packaging the app to Docker
# create the Dockerfile.txt
<!-- it will use dockerfile to build an image -->
```bash
docker build -t ride-duration-prediction-service:v1 .
```
<!-- test the docker image -->
```bash
docker run -it --rm -p 9696:9696  ride-duration-prediction-service:v1
```



## 4.3 Getting the model for deployment from MLflow

* Take the code from the previous video
* Train another model, register with MLflow
* Put the model into a scikit-learn pipeline
* Model deployment with tracking server
* Model deployment without the tracking server

## install package
pipenv install --dev mlflow

Starting the MLflow server with S3:

```bash
mlflow server \
    --backend-store-uri=sqlite:///mlflow.db \
    --default-artifact-root=s3://mlflow-models-alexey/
```

Downloading the artifact

```bash
export MLFLOW_TRACKING_URI="http://127.0.0.1:5000"
export MODEL_RUN_ID="6dd459b11b4e48dc862f4e1019d166f6"
# used for os.getenv('RUN_ID')

mlflow artifacts download \
    --run-id ${MODEL_RUN_ID} \
    --artifact-path model \
    --dst-path .
```